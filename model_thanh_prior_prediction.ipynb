{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPL Dataset\\2005-2006.csv\n",
      "EPL Dataset\\2006-2007.csv\n",
      "EPL Dataset\\2007-2008.csv\n",
      "EPL Dataset\\2008-2009.csv\n",
      "EPL Dataset\\2009-2010.csv\n",
      "EPL Dataset\\2010-2011.csv\n",
      "EPL Dataset\\2011-2012.csv\n",
      "EPL Dataset\\2012-2013.csv\n",
      "EPL Dataset\\2013-2014.csv\n",
      "EPL Dataset\\2014-2015.csv\n",
      "EPL Dataset\\2015-2016.csv\n",
      "EPL Dataset\\2016-2017.csv\n",
      "EPL Dataset\\2017-2018.csv\n",
      "EPL Dataset\\2018-2019.csv\n",
      "EPL Dataset\\2019-2020.csv\n",
      "EPL Dataset\\2020-2021.csv\n",
      "EPL Dataset\\2021-2022.csv\n",
      "EPL Dataset\\2022-2023.csv\n",
      "EPL Dataset\\2023-2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a joined pandas file\n",
    "joined_files = os.path.join(\"EPL Dataset\", \"*.csv\")\n",
    "joined_list = glob.glob(joined_files)\n",
    "li = []\n",
    "\n",
    "for filename in joined_list[12:]:\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "dataset = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = dataset[['B365H','B365D','B365A','BWH','BWD','BWA','IWH','IWD','IWA','LBH','LBD','LBA','WHH','WHD','WHA', 'VCH',\t'VCD','VCA']]\n",
    "df_features = df_features.interpolate(method='linear')\n",
    "result = dataset['FTR']\n",
    "\n",
    "result = pd.factorize(result)\n",
    "features = np.array(df_features)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "result = np.array(result[0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5517730496453901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5191489361702127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "print(accuracy_score(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16076839 -0.65507402 -0.47788563 ... -0.16462063 -0.51749062\n",
      "  -0.44467708]\n",
      " [-0.49071445 -0.24457833 -0.02754928 ... -0.47514012 -0.22569399\n",
      "  -0.07629179]\n",
      " [-0.73694285  0.37116521  1.71840714 ... -0.72355571  0.39958451\n",
      "   0.93676776]\n",
      " ...\n",
      " [ 0.82414522 -0.36772704 -0.71148256 ...  0.70961115 -0.35074969\n",
      "  -0.69333715]\n",
      " [ 0.13470569 -0.69612359 -0.62960322 ...  0.16978497 -0.64254632\n",
      "  -0.65189381]\n",
      " [ 0.18395137 -0.65507402 -0.61756214 ...  0.07424051 -0.60086109\n",
      "  -0.58282156]]\n",
      "-0.21536067358200697\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "test = []\n",
    "print(X_val)\n",
    "for i in range(0, len(y_val)):\n",
    "    if(y_val[i] == y_pred[i]):\n",
    "        if (y_val[i] == 0):\n",
    "            test.append(X_val[i][2])\n",
    "        if (y_val[i] == 1):\n",
    "            test.append(X_val[i][1])\n",
    "        if (y_val[i] == 2):\n",
    "            test.append(X_val[i][0])\n",
    "    else:\n",
    "        test.append(0)\n",
    "print(sum(test) / len(test))\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
